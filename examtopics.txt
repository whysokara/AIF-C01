>> Real-Time Inference: Immediate responses for high-traffic, low-latency applications. 
>> Asynchronous Inference: Near real-time for large payloads and longer processing. 
>> Batch Transform: Large-scale, offline processing without real-time needs. 
>> Serverless Inference: Low-latency inference for intermittent or unpredictable traffic without managing infrastructure.